{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3d5f2eb-5d31-4305-b8ba-3710966ab3c1",
   "metadata": {},
   "source": [
    "# Grad-CAM Implementation for Retinal Image Dataset\n",
    "\n",
    "This notebook demonstrates how to use Grad-CAM (Gradient-weighted Class Activation Mapping) to visualize important regions of an image that contribute to a deep learning model's prediction. The model used is a CNN (Convolutional Neural Network) trained to classify retinal images into two classes: **Non-CVD** (label 0) and **CVD** (label 1).\n",
    "\n",
    "### Code Implementation\n",
    "\n",
    "The following code performs the following steps:\n",
    "\n",
    "1. **Loading the model**: The pre-trained CNN model is loaded from the file `model.h5`.\n",
    "2. **Compiling the model**: The model is compiled with a dummy optimizer and loss function to ensure layers are initialized properly.\n",
    "3. **Loading the dataset**: The dataset consists of retinal images stored in folders `0` and `1`, representing the classes **Non-CVD** and **CVD**, respectively.\n",
    "4. **Selecting random images**: Three random images are selected from the dataset for visualization.\n",
    "5. **Computing Grad-CAM**: Grad-CAM is applied to the selected images, and the heatmaps are visualized alongside the original images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4019396-aa9f-4f56-8057-856996110679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "The layer sequential has never been called and thus has no defined output.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 80\u001b[0m\n\u001b[0;32m     77\u001b[0m label \u001b[38;5;241m=\u001b[39m selected_labels[i]\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Compute Grad-CAM for this image\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m heatmap \u001b[38;5;241m=\u001b[39m compute_gradcam(model, image, label)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Plot the original image with the Grad-CAM overlay\u001b[39;00m\n\u001b[0;32m     83\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n",
      "Cell \u001b[1;32mIn[6], line 47\u001b[0m, in \u001b[0;36mcompute_gradcam\u001b[1;34m(model, image, label, layer_name)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Get the model's last convolutional layer and its output\u001b[39;00m\n\u001b[0;32m     44\u001b[0m last_conv_layer \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_layer(layer_name)\n\u001b[0;32m     45\u001b[0m heatmap_model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mModel(\n\u001b[0;32m     46\u001b[0m     inputs\u001b[38;5;241m=\u001b[39m[model\u001b[38;5;241m.\u001b[39minputs],\n\u001b[1;32m---> 47\u001b[0m     outputs\u001b[38;5;241m=\u001b[39m[last_conv_layer\u001b[38;5;241m.\u001b[39moutput, model\u001b[38;5;241m.\u001b[39moutput]\n\u001b[0;32m     48\u001b[0m )\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m     51\u001b[0m     conv_output, predictions \u001b[38;5;241m=\u001b[39m heatmap_model(image_input)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py:266\u001b[0m, in \u001b[0;36mOperation.output\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moutput\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    258\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Retrieves the output tensor(s) of a layer.\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \n\u001b[0;32m    260\u001b[0m \u001b[38;5;124;03m    Only returns the tensor(s) corresponding to the *first time*\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m        Output tensor or list of output tensors.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_node_attribute_at_index(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py:285\u001b[0m, in \u001b[0;36mOperation._get_node_attribute_at_index\u001b[1;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Private utility to retrieves an attribute (e.g. inputs) from a node.\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03mThis is used to implement the properties:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;124;03m    The operation's attribute `attr` at the node of index `node_index`.\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    286\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has never been called \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    287\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand thus has no defined \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    288\u001b[0m     )\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes) \u001b[38;5;241m>\u001b[39m node_index:\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    291\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to get \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at node \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    292\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but the operation has only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    293\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m inbound nodes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    294\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: The layer sequential has never been called and thus has no defined output."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the model\n",
    "model = load_model('model.h5')\n",
    "\n",
    "# Compile the model to initialize the layers properly\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Function to load and preprocess dataset\n",
    "def load_data(dataset_path, img_size=(224, 224)):\n",
    "    data, labels = [], []\n",
    "    for label in [0, 1]:  # 0: Non-CVD, 1: CVD\n",
    "        folder_path = os.path.join(dataset_path, str(label))\n",
    "        for img_file in os.listdir(folder_path):\n",
    "            img_path = os.path.join(folder_path, img_file)\n",
    "            try:\n",
    "                img = cv2.imread(img_path)\n",
    "                img = cv2.resize(img, img_size)\n",
    "                data.append(img)\n",
    "                labels.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {img_path}: {e}\")\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# Select 3 random images for Grad-CAM\n",
    "data, labels = load_data('data')  # Path to the 'data' folder containing '0' and '1'\n",
    "indices = np.random.choice(len(data), 3, replace=False)\n",
    "selected_images = data[indices]\n",
    "selected_labels = labels[indices]\n",
    "\n",
    "# Function to compute Grad-CAM\n",
    "def compute_gradcam(model, image, label, layer_name='conv2d_2'):\n",
    "    # Prepare the image for prediction\n",
    "    image_input = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    image_input = image_input / 255.0  # Normalize\n",
    "\n",
    "    # Get the model's last convolutional layer and its output\n",
    "    last_conv_layer = model.get_layer(layer_name)\n",
    "    heatmap_model = tf.keras.models.Model(\n",
    "        inputs=[model.inputs],\n",
    "        outputs=[last_conv_layer.output, model.output]\n",
    "    )\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_output, predictions = heatmap_model(image_input)\n",
    "        loss = predictions[:, label]\n",
    "    \n",
    "    # Compute the gradients of the loss with respect to the last convolutional layer\n",
    "    grads = tape.gradient(loss, conv_output)\n",
    "    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "    \n",
    "    # Multiply the gradients with the convolutional output\n",
    "    conv_output = conv_output[0]\n",
    "    pooled_grads = pooled_grads.numpy()\n",
    "    conv_output = conv_output.numpy()\n",
    "    \n",
    "    for i in range(conv_output.shape[-1]):\n",
    "        conv_output[:, :, i] *= pooled_grads[i]\n",
    "    \n",
    "    # Generate the heatmap\n",
    "    heatmap = np.mean(conv_output, axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "\n",
    "    # Resize heatmap to match the image size\n",
    "    heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))\n",
    "    return heatmap\n",
    "\n",
    "# Visualize the Grad-CAM for the selected images\n",
    "for i, image in enumerate(selected_images):\n",
    "    label = selected_labels[i]\n",
    "    \n",
    "    # Compute Grad-CAM for this image\n",
    "    heatmap = compute_gradcam(model, image, label)\n",
    "    \n",
    "    # Plot the original image with the Grad-CAM overlay\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f'Original Image (Label: {label})')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.imshow(heatmap, cmap='jet', alpha=0.5)  # Overlay heatmap with 50% transparency\n",
    "    plt.title(f'Grad-CAM (Label: {label})')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682b40a6-d100-4393-96d3-8d3cdd4d5016",
   "metadata": {},
   "source": [
    "### Note on Grad-CAM Error\n",
    "\n",
    "<span style=\"color:green\">I faced a challenge while implementing Grad-CAM for the first time. Unfortunately, due to time constraints, I was unable to resolve the error fully this time. However, I tried my best to follow the steps, and I believe I’ve captured the key aspects of the process. I will revisit this in the future and ensure the implementation is smooth and works perfectly.</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c9c006-b152-4777-ad2f-388993332c79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
